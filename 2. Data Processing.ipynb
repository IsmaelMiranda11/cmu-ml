{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering and missing values filling strategies for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/spaceshit-titanic/train.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of missing values</th>\n",
       "      <th>Type</th>\n",
       "      <th>Distinct values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <td>0</td>\n",
       "      <td>bool</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>179</td>\n",
       "      <td>float64</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>181</td>\n",
       "      <td>float64</td>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>183</td>\n",
       "      <td>float64</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>208</td>\n",
       "      <td>float64</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>183</td>\n",
       "      <td>float64</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>188</td>\n",
       "      <td>float64</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>8693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>201</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>217</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>199</td>\n",
       "      <td>object</td>\n",
       "      <td>6560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>182</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>203</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>200</td>\n",
       "      <td>object</td>\n",
       "      <td>8473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number of missing values     Type  Distinct values\n",
       "Transported                          0     bool                2\n",
       "Age                                179  float64               80\n",
       "RoomService                        181  float64             1273\n",
       "FoodCourt                          183  float64             1507\n",
       "ShoppingMall                       208  float64             1115\n",
       "Spa                                183  float64             1327\n",
       "VRDeck                             188  float64             1306\n",
       "PassengerId                          0   object             8693\n",
       "HomePlanet                         201   object                3\n",
       "CryoSleep                          217   object                2\n",
       "Cabin                              199   object             6560\n",
       "Destination                        182   object                3\n",
       "VIP                                203   object                2\n",
       "Name                               200   object             8473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Number of missing values':df.isnull().sum(), \n",
    "        'Type': df.dtypes,\n",
    "        'Distinct values': df.nunique()\n",
    "    }\n",
    ").sort_values(by='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Name** and **Cabin** columns have mostly of unique values (high cardinality), such as the **PassengerId**.\n",
    "\n",
    "But, **Cabin** and **PassengerId** have a pattern that can be used to extract new information by splitting the values.\n",
    "\n",
    "**Name**, on the other hand, can not be used directly, so, it will be desconsidered in training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PassengerId** has the pattern *gggg_pp* where *gggg* indicates a group the passenger is travelling with and *pp* is their number within the group. So, two columns will arise: **Group** and **Number**.\n",
    "\n",
    "These information could be useful to predict the tranportation of the passengers, but need be tested after the model is trained.\n",
    "\n",
    "**Cabin** has the pattern *deck/num/side*. Again, these information could be useful and will be evaluated after the model is trained. This time, three columns will arise: **Deck**, **Num** and **Side**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical columns need to be encoded in order to be fitted in the model.\n",
    "\n",
    "The following columns will be encoded:\n",
    "- **Deck** (from **Cabin**)\n",
    "- **Side** (from **Cabin**)\n",
    "- **VIP** \n",
    "- **CryoSleep**\n",
    "- **HomePlanet**\n",
    "- **Destination**\n",
    "\n",
    "As said above, the **Name** column will be dropped.  \n",
    "\n",
    "The **Group**, **Number** (from **PassengerId**) and **Num** (from **Cabin**) columns will be kept as integers, since they are already numerical.\n",
    "\n",
    "### Two-step encoding\n",
    "\n",
    "In a first step, the string classes will be turned into integers through a simple encoder. \n",
    "\n",
    "After replacing missing values (read more below), the columns will be one-hot encoded, which will create a new bollean column for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical fields\n",
    "\n",
    "- The follwing strategies might be apply to fill missing values in numerical fields:\n",
    "  - Fill with the median value\n",
    "  - Fill with the mean value\n",
    "  - Fill with the mode value\n",
    "  - Fill with a constant value\n",
    "  - Drop the rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical fields\n",
    "\n",
    "- **PassengerId** - No missing values. So, the **Group** and **Number** will have no missing values too.\n",
    "\n",
    "- Just to remember, **Name** is a high cardinality field, so it will be dropped.\n",
    "\n",
    "- **VIP** and **CryoSleep**: both columns are True/False fields, so for the missing values it could be try the approaches:\n",
    "  - Replaced by most frequent value.\n",
    "  - Replaced by the False value (thereby, the absence of information is the negative answer).\n",
    "  - Drop the rows with missing values.\n",
    "\n",
    "- **HomePlanet** and **Destination** have more than 2 classes each. Possible strategies:\n",
    "  - A classifier could be used to fill the missing values based on the other fields.\n",
    "  - Replaced by the most frequent value.\n",
    "  - Replaced by a constant value.\n",
    "  - Drop the rows with missing values.\n",
    "\n",
    "- For **Deck**, **Num** and **Side** will have missing values after the feature engineering of the **Cabin** field. The following strategies could be applied:\n",
    "  - A classifier could be used to fill the missing values based on the other fields.\n",
    "  - Replaced by the most frequent value.\n",
    "  - Replaced by a constant value.\n",
    "  - Drop the rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sckit-learn transformers pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data processing, a scikit-learn pipeline will be used to apply the stated above strategies.\n",
    "\n",
    "A pipeline is a sequence of transformers followed by a final estimator. The transformers are applied to the data in the order they are added to the pipeline.\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('step1', transformer1),\n",
    "    ('step2', transformer2),\n",
    "    ...\n",
    "    ('stepN', transformerN),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "```\n",
    "\n",
    "The intermediates transformers are apply to the whole `X` dataset, while the estimator is applied with `y` together.\n",
    "\n",
    "### Different transformers for different columns types\n",
    "\n",
    "As the project dataset has different types of columns, the ColumnTransformer will be used to apply different transformers to different columns. ColumnTransformer is a special kind of pipeline that applies different transformations to different columns, specified by a list (columns labels or indexes)\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "```\n",
    "\n",
    "After defining a ColumnTransformer, it can be used in a pipeline as a transformer.\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "```\n",
    "\n",
    "In that manner, the pipeline will apply the transformations into right columns at each step.\n",
    "\n",
    "\n",
    "### Custom transformers for feature engineering\n",
    "\n",
    "Besides the scikit-learn transformers, custom transformers can be created to apply feature engineering. FunctionTransformer is a manner to attach a custom function to the pipeline. In combination with the ColumnTransformer, it can be used to apply feature engineering to specific columns.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def feature_engineering(X):\n",
    "    # do something with X\n",
    "    return X\n",
    "\n",
    "feature_engineering = FunctionTransformer(feature_engineering)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('feature_engineering', feature_engineering, feature_engineering_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all the information above, the pipeline will be created to process the data and train the model.\n",
    "\n",
    "Below, the code for the project transformers pipeline is presented.\n",
    "\n",
    "The complete pipeline, with the final step estimator, will be defined in the `Training` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note: this code would be different from the final code, since the final code will be modified through the project development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.711945</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.334037</td>\n",
       "      <td>-0.168073</td>\n",
       "      <td>-0.275387</td>\n",
       "      <td>-0.241771</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.224205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.036857</td>\n",
       "      <td>-0.268001</td>\n",
       "      <td>1.959998</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>5.695623</td>\n",
       "      <td>-0.219796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.293552</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.523010</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>2.687176</td>\n",
       "      <td>-0.092818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.891895</td>\n",
       "      <td>0.125652</td>\n",
       "      <td>-0.237159</td>\n",
       "      <td>-0.031059</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>-0.261240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>3.992336</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>1.189173</td>\n",
       "      <td>-0.197751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.752431</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.194573</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>2.846999</td>\n",
       "      <td>-0.269737</td>\n",
       "      <td>-0.263003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223820</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.376365</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>2.589576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.060606</td>\n",
       "      <td>-0.142335</td>\n",
       "      <td>2.656871</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.252422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Group  Deck     Num  Side  VIP  CryoSleep  HomePlanet  Destination  \\\n",
       "0        1.0   1.0     0.0   0.0  0.0        0.0         1.0          2.0   \n",
       "1        2.0   5.0     0.0   1.0  0.0        0.0         0.0          2.0   \n",
       "2        3.0   0.0     0.0   1.0  1.0        0.0         1.0          2.0   \n",
       "3        3.0   0.0     0.0   1.0  0.0        0.0         1.0          2.0   \n",
       "4        4.0   5.0     1.0   1.0  0.0        0.0         0.0          2.0   \n",
       "...      ...   ...     ...   ...  ...        ...         ...          ...   \n",
       "8688  9276.0   0.0    98.0   0.0  1.0        0.0         1.0          0.0   \n",
       "8689  9278.0   6.0  1499.0   1.0  0.0        1.0         0.0          1.0   \n",
       "8690  9279.0   6.0  1500.0   1.0  0.0        0.0         0.0          2.0   \n",
       "8691  9280.0   4.0   608.0   1.0  0.0        0.0         1.0          0.0   \n",
       "8692  9280.0   4.0   608.0   1.0  0.0        0.0         1.0          2.0   \n",
       "\n",
       "           Age  RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  \n",
       "0     0.711945    -0.333105  -0.281027     -0.283579 -0.270626 -0.263003  \n",
       "1    -0.334037    -0.168073  -0.275387     -0.241771  0.217158 -0.224205  \n",
       "2     2.036857    -0.268001   1.959998     -0.283579  5.695623 -0.219796  \n",
       "3     0.293552    -0.333105   0.523010      0.336851  2.687176 -0.092818  \n",
       "4    -0.891895     0.125652  -0.237159     -0.031059  0.231374 -0.261240  \n",
       "...        ...          ...        ...           ...       ...       ...  \n",
       "8688  0.851410    -0.333105   3.992336     -0.283579  1.189173 -0.197751  \n",
       "8689 -0.752431    -0.333105  -0.281027     -0.283579 -0.270626 -0.263003  \n",
       "8690 -0.194573    -0.333105  -0.281027      2.846999 -0.269737 -0.263003  \n",
       "8691  0.223820    -0.333105   0.376365     -0.283579  0.043013  2.589576  \n",
       "8692  1.060606    -0.142335   2.656871     -0.283579 -0.270626 -0.252422  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline   import Pipeline\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "\n",
    "## 1. Columns separation\n",
    "# Categorical columns\n",
    "categorical_columns = [\n",
    "    'Group', # it will be created by the passenger_id_spliter\n",
    "    'Deck', # it will be created by the cabin_spliter\n",
    "    'Num', # it will be created by the cabin_spliter\n",
    "    'Side', # it will be created by the cabin_spliter\n",
    "    'VIP',\n",
    "    'CryoSleep',\n",
    "    'HomePlanet',\n",
    "    'Destination'\n",
    "]\n",
    "# Categorical columns to encode. They have low cardinality\n",
    "columns_to_encode = [\n",
    "    'Deck', # it will be created by the cabin_spliter\n",
    "    'Side', # it will be created by the cabin_spliter\n",
    "    'VIP',\n",
    "    'CryoSleep',\n",
    "    'HomePlanet',\n",
    "    'Destination'\n",
    "]\n",
    "\n",
    "# Numeric columns\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "## 2. FunctionTransformers. Custom transformers for columns\n",
    "# Function\n",
    "def passenger_id_spliter(passenger_id_col: pd.Series) -> pd.DataFrame:\n",
    "    '''Function to split the passenger id into two columns\n",
    "\n",
    "    Args:\n",
    "        passenger_id_col: pd.Series - The passenger id column\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame - The dataframe with the two columns (Group, Number)\n",
    "    '''\n",
    "    df = (\n",
    "        pd.DataFrame(\n",
    "            passenger_id_col\n",
    "            .str\n",
    "            .split('_')\n",
    "            .to_list(),\n",
    "        columns=['Group', 'Number'],\n",
    "        index=passenger_id_col.index\n",
    "        )\n",
    "        .drop('Number', axis=1)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def cabin_spliter(cabin_col: pd.Series) -> pd.DataFrame:\n",
    "    '''Function to split the cabin into two columns\n",
    "\n",
    "    Args:\n",
    "        cabin_col: pd.Series - The cabin column\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame - The dataframe with three columns (Deck, Num, Side)\n",
    "    '''\n",
    "    df = (\n",
    "        cabin_col\n",
    "        .str\n",
    "        .split('/', expand=True)\n",
    "        .rename(columns={0: 'Deck', 1: 'Num', 2: 'Side'})\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "## 3. Transformer instantiation\n",
    "\n",
    "# Custom transformers\n",
    "passenger_id_transformer = FunctionTransformer(func=passenger_id_spliter,\n",
    "    feature_names_out=lambda _, __: np.array(['Group'])\n",
    ")\n",
    "\n",
    "cabin_transformer = FunctionTransformer(func=cabin_spliter,\n",
    "    feature_names_out=lambda _, __: np.array(['Deck', 'Num', 'Side'])\n",
    ")\n",
    "\n",
    "# Encoders\n",
    "encoder = OrdinalEncoder()\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Scalers\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Imputer\n",
    "knn = KNNImputer(n_neighbors=10, weights='uniform')\n",
    "simple_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Rounder for the categorical columns\n",
    "rounder = FunctionTransformer(func=lambda x: np.round(x, 0),\n",
    "    feature_names_out=lambda _, __: categorical_columns\n",
    ")\n",
    "\n",
    "## 4. Transformers pipeline\n",
    "\n",
    "# Columns splitter function transformer\n",
    "splitter_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('passenger_id', passenger_id_transformer, 'PassengerId'),\n",
    "        ('cabin', cabin_transformer, 'Cabin')\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False, #type: ignore\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Enconder the categorical columns\n",
    "encoder_transfomer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', encoder, columns_to_encode)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False, #type: ignore\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Imputers and dropping high cardinality columns\n",
    "imputer_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_imputer', simple_imputer, numeric_columns),\n",
    "        ('categorical_imputer', knn, categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False, #type: ignore\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Rounder and scalers\n",
    "rounder_scaler_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('rounder', rounder, categorical_columns),\n",
    "        ('scaler', scaler, numeric_columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False, #type: ignore\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Dropping columns\n",
    "drop_columns_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop', 'drop', 'Name')\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False, #type: ignore\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Gather all transformers into a pipeline\n",
    "transfomers = Pipeline([\n",
    "    ('splitter', splitter_transformer),\n",
    "    ('encoder', encoder_transfomer),\n",
    "    ('imputer', imputer_transformer),\n",
    "    ('rounder_scaler', rounder_scaler_transformer),\n",
    "    ('drop_columns', drop_columns_transformer)\n",
    "])\n",
    "\n",
    "# Garantee that the output of \"transform\" and \"fit_transform\" will be a pandas dataframe\n",
    "# This is necessary due use label columns into transformers\n",
    "transfomers.set_output(transform='pandas')\n",
    "\n",
    "## 5. Fit and transform the data\n",
    "transfomers.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
